{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.5 64-bit"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "CS224W - Colab 0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "interpreter": {
      "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuXWJLEm2UWS"
      },
      "source": [
        "# **CS224W - Colab 0**\n",
        "\n",
        "Colab 0 **will not be graded**, so you don't need to hand in this notebook. That said, we highly recommend you to run this notebook, so you can get familiar with the basic concepts of graph mining and Graph Neural Networks.\n",
        "\n",
        "In this Colab, we will introduce two packages, [NetworkX](https://networkx.org/documentation/stable/) and [PyTorch Geometric](https://pytorch-geometric.readthedocs.io/en/latest/).\n",
        "\n",
        "For the PyTorch Geometric section, you don't need to understand all the details already. Concepts and implementations of graph neural network will be covered in future lectures and Colabs.\n",
        "\n",
        "Please make a copy before you proceed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIUjFBAcdaHX"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gzsP50bF6Gb"
      },
      "source": [
        "\n",
        "# NetworkX Tutorial\n",
        "\n",
        "NetworkX is one of the most frequently used Python packages to create, manipulate, and mine graphs.\n",
        "\n",
        "Main parts of this tutorial are adapted from https://colab.research.google.com/github/jdwittenauer/ipython-notebooks/blob/master/notebooks/libraries/NetworkX.ipynb#scrollTo=zA1OO6huHeV6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nwwq0nSdmsOL"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeqN7MHvH1OA"
      },
      "source": [
        "# Import the NetworkX package\n",
        "import networkx as nx"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCIeGAfLfAMK"
      },
      "source": [
        "## Graph\n",
        "NetworkX provides several classes to store different types of graphs, such as directed and undirected graph. It also provides classes to create multigraphs (both directed and undirected).\n",
        "\n",
        "For more information, please refer to [NetworkX graph types](https://networkx.org/documentation/stable/reference/classes/index.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSI_n6P-e0PW"
      },
      "source": [
        "# Create an undirected graph G\n",
        "G = nx.Graph()\n",
        "print(G.is_directed())\n",
        "\n",
        "# Create a directed graph H\n",
        "H = nx.DiGraph()\n",
        "print(H.is_directed())\n",
        "\n",
        "# Add graph level attribute\n",
        "G.graph[\"Name\"] = \"Bar\"\n",
        "print(G.graph)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\nTrue\n{'Name': 'Bar'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0pLs0-Ka9j8"
      },
      "source": [
        "## Node\n",
        "\n",
        "Nodes (with attributes) can be easily added to NetworkX graphs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQ8ApAL5H1GB"
      },
      "source": [
        "# Add one node with node level attributes\n",
        "G.add_node(0, feature=0, label=0)\n",
        "\n",
        "# Get attributes of the node 0\n",
        "node_0_attr = G.nodes[0]\n",
        "print(\"Node 0 has the attributes {}\".format(node_0_attr))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node 0 has the attributes {'feature': 0, 'label': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btOdMYqJaKia"
      },
      "source": [
        "# Add multiple nodes with attributes\n",
        "G.add_nodes_from([\n",
        "  (1, {\"feature\": 1, \"label\": 1}),\n",
        "  (2, {\"feature\": 2, \"label\": 2})\n",
        "])\n",
        "\n",
        "# Loop through all the nodes\n",
        "# Set data=True will return node attributes\n",
        "for node in G.nodes(data=True):\n",
        "  print(node)\n",
        "\n",
        "# Get number of nodes\n",
        "num_nodes = G.number_of_nodes()\n",
        "print(\"G has {} nodes\".format(num_nodes))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, {'feature': 0, 'label': 0})\n(1, {'feature': 1, 'label': 1})\n(2, {'feature': 2, 'label': 2})\nG has 3 nodes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AdoaZPgbRis"
      },
      "source": [
        "## Edge\n",
        "\n",
        "Similar to nodes, edges (with attributes) can also be easily added to NetworkX graphs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0szH5F6EH079"
      },
      "source": [
        "# Add one edge with edge weight 0.5\n",
        "G.add_edge(0, 1, weight=0.5)\n",
        "\n",
        "# Get attributes of the edge (0, 1)\n",
        "edge_0_1_attr = G.edges[(0, 1)]\n",
        "print(\"Edge (0, 1) has the attributes {}\".format(edge_0_1_attr))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Edge (0, 1) has the attributes {'weight': 0.5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRTmi4EUaf_I"
      },
      "source": [
        "# Add multiple edges with edge weights\n",
        "G.add_edges_from([\n",
        "  (1, 2, {\"weight\": 0.3}),\n",
        "  (2, 0, {\"weight\": 0.1})\n",
        "])\n",
        "\n",
        "# Loop through all the edges\n",
        "# Here there is no data=True, so only the edge will be returned\n",
        "for edge in G.edges():\n",
        "  print(edge)\n",
        "\n",
        "# Get number of edges\n",
        "num_edges = G.number_of_edges()\n",
        "print(\"G has {} edges\".format(num_edges))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, 1)\n(0, 2)\n(1, 2)\nG has 3 edges\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9u1Utjn4bc7k"
      },
      "source": [
        "## Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lykPzFOEahuP"
      },
      "source": [
        "# Draw the graph\n",
        "nx.draw(G, with_labels = True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"302.4pt\" version=\"1.1\" viewBox=\"0 0 446.4 302.4\" width=\"446.4pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-06-14T14:00:58.109742</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.4, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 302.4 \nL 446.4 302.4 \nL 446.4 0 \nL 0 0 \nz\n\" style=\"fill:#ffffff;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"LineCollection_1\">\n    <path clip-path=\"url(#p5e51c15d7d)\" d=\"M 26.836364 282.109091 \nL 419.563636 196.696239 \n\" style=\"fill:none;stroke:#000000;\"/>\n    <path clip-path=\"url(#p5e51c15d7d)\" d=\"M 26.836364 282.109091 \nL 232.710429 20.290909 \n\" style=\"fill:none;stroke:#000000;\"/>\n    <path clip-path=\"url(#p5e51c15d7d)\" d=\"M 419.563636 196.696239 \nL 232.710429 20.290909 \n\" style=\"fill:none;stroke:#000000;\"/>\n   </g>\n   <g id=\"PathCollection_1\">\n    <defs>\n     <path d=\"M 0 8.660254 \nC 2.296726 8.660254 4.499694 7.747755 6.123724 6.123724 \nC 7.747755 4.499694 8.660254 2.296726 8.660254 0 \nC 8.660254 -2.296726 7.747755 -4.499694 6.123724 -6.123724 \nC 4.499694 -7.747755 2.296726 -8.660254 0 -8.660254 \nC -2.296726 -8.660254 -4.499694 -7.747755 -6.123724 -6.123724 \nC -7.747755 -4.499694 -8.660254 -2.296726 -8.660254 0 \nC -8.660254 2.296726 -7.747755 4.499694 -6.123724 6.123724 \nC -4.499694 7.747755 -2.296726 8.660254 0 8.660254 \nz\n\" id=\"m2608cc23fb\" style=\"stroke:#1f78b4;\"/>\n    </defs>\n    <g clip-path=\"url(#p5e51c15d7d)\">\n     <use style=\"fill:#1f78b4;stroke:#1f78b4;\" x=\"26.836364\" xlink:href=\"#m2608cc23fb\" y=\"282.109091\"/>\n     <use style=\"fill:#1f78b4;stroke:#1f78b4;\" x=\"419.563636\" xlink:href=\"#m2608cc23fb\" y=\"196.696239\"/>\n     <use style=\"fill:#1f78b4;stroke:#1f78b4;\" x=\"232.710429\" xlink:href=\"#m2608cc23fb\" y=\"20.290909\"/>\n    </g>\n   </g>\n   <g id=\"text_1\">\n    <g clip-path=\"url(#p5e51c15d7d)\">\n     <!-- 0 -->\n     <g transform=\"translate(23.018864 285.420341)scale(0.12 -0.12)\">\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-48\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_2\">\n    <g clip-path=\"url(#p5e51c15d7d)\">\n     <!-- 1 -->\n     <g transform=\"translate(415.746136 200.007489)scale(0.12 -0.12)\">\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-49\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_3\">\n    <g clip-path=\"url(#p5e51c15d7d)\">\n     <!-- 2 -->\n     <g transform=\"translate(228.892929 23.602159)scale(0.12 -0.12)\">\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-50\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p5e51c15d7d\">\n   <rect height=\"288\" width=\"432\" x=\"7.2\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Q6YTP2FDbOS"
      },
      "source": [
        "## Node Degree and Neighbor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFA3B6Z_DE3q"
      },
      "source": [
        "node_id = 1\n",
        "\n",
        "# Degree of node 1\n",
        "print(\"Node {} has degree {}\".format(node_id, G.degree[node_id]))\n",
        "\n",
        "# Get neighbor of node 1\n",
        "for neighbor in G.neighbors(node_id):\n",
        "  print(\"Node {} has neighbor {}\".format(node_id, neighbor))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node 1 has degree 2\nNode 1 has neighbor 0\nNode 1 has neighbor 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gVRVckZeSdA"
      },
      "source": [
        "## Other Functionalities\n",
        "\n",
        "NetworkX also provides plenty of useful methods to study graphs.\n",
        "\n",
        "Here is an example to get [PageRank](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.link_analysis.pagerank_alg.pagerank.html#networkx.algorithms.link_analysis.pagerank_alg.pagerank) of nodes (we will talk about PageRank in one of the future lectures)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gZfQ82Wiuvv"
      },
      "source": [
        "num_nodes = 4\n",
        "# Create a new path like graph and change it to a directed graph\n",
        "G = nx.DiGraph(nx.path_graph(num_nodes))\n",
        "nx.draw(G, with_labels = True)\n",
        "\n",
        "# Get the PageRank\n",
        "pr = nx.pagerank(G, alpha=0.8)\n",
        "pr"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0.17857162031103999,\n",
              " 1: 0.32142837968896,\n",
              " 2: 0.32142837968896,\n",
              " 3: 0.17857162031103999}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"302.4pt\" version=\"1.1\" viewBox=\"0 0 446.4 302.4\" width=\"446.4pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-06-14T14:00:58.330709</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.4, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 302.4 \nL 446.4 302.4 \nL 446.4 0 \nL 0 0 \nz\n\" style=\"fill:#ffffff;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path clip-path=\"url(#p0017f4a861)\" d=\"M 394.505715 265.403772 \nQ 344.141715 231.827508 294.707974 198.871421 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;\"/>\n    <path clip-path=\"url(#p0017f4a861)\" d=\"M 296.926761 202.754331 \nL 294.707974 198.871421 \nL 299.145573 199.426137 \nL 296.926761 202.754331 \nz\n\" style=\"stroke:#000000;stroke-linecap:round;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path clip-path=\"url(#p0017f4a861)\" d=\"M 293.780835 198.253324 \nQ 344.144835 231.829588 393.578576 264.785675 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;\"/>\n    <path clip-path=\"url(#p0017f4a861)\" d=\"M 391.35979 260.902765 \nL 393.578576 264.785675 \nL 389.140977 264.230959 \nL 391.35979 260.902765 \nz\n\" style=\"stroke:#000000;stroke-linecap:round;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path clip-path=\"url(#p0017f4a861)\" d=\"M 279.368238 188.644888 \nQ 223.201773 151.200578 167.965568 114.376442 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;\"/>\n    <path clip-path=\"url(#p0017f4a861)\" d=\"M 170.184369 118.259343 \nL 167.965568 114.376442 \nL 172.40317 114.931142 \nL 170.184369 118.259343 \nz\n\" style=\"stroke:#000000;stroke-linecap:round;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path clip-path=\"url(#p0017f4a861)\" d=\"M 167.036418 113.757008 \nQ 223.202884 151.201318 278.439089 188.025455 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;\"/>\n    <path clip-path=\"url(#p0017f4a861)\" d=\"M 276.220288 184.142554 \nL 278.439089 188.025455 \nL 274.001487 187.470755 \nL 276.220288 184.142554 \nz\n\" style=\"stroke:#000000;stroke-linecap:round;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path clip-path=\"url(#p0017f4a861)\" d=\"M 152.62353 104.148454 \nQ 102.257494 70.571361 52.82172 37.614437 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;\"/>\n    <path clip-path=\"url(#p0017f4a861)\" d=\"M 55.040534 41.49733 \nL 52.82172 37.614437 \nL 57.259323 38.169121 \nL 55.040534 41.49733 \nz\n\" style=\"stroke:#000000;stroke-linecap:round;\"/>\n   </g>\n   <g id=\"patch_7\">\n    <path clip-path=\"url(#p0017f4a861)\" d=\"M 51.894576 36.996346 \nQ 102.260613 70.57344 151.696387 103.530364 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:round;\"/>\n    <path clip-path=\"url(#p0017f4a861)\" d=\"M 149.477572 99.64747 \nL 151.696387 103.530364 \nL 147.258783 102.975679 \nL 149.477572 99.64747 \nz\n\" style=\"stroke:#000000;stroke-linecap:round;\"/>\n   </g>\n   <g id=\"PathCollection_1\">\n    <defs>\n     <path d=\"M 0 8.660254 \nC 2.296726 8.660254 4.499694 7.747755 6.123724 6.123724 \nC 7.747755 4.499694 8.660254 2.296726 8.660254 0 \nC 8.660254 -2.296726 7.747755 -4.499694 6.123724 -6.123724 \nC 4.499694 -7.747755 2.296726 -8.660254 0 -8.660254 \nC -2.296726 -8.660254 -4.499694 -7.747755 -6.123724 -6.123724 \nC -7.747755 -4.499694 -8.660254 -2.296726 -8.660254 0 \nC -8.660254 2.296726 -7.747755 4.499694 -6.123724 6.123724 \nC -4.499694 7.747755 -2.296726 8.660254 0 8.660254 \nz\n\" id=\"md227f39d3a\" style=\"stroke:#1f78b4;\"/>\n    </defs>\n    <g clip-path=\"url(#p0017f4a861)\">\n     <use style=\"fill:#1f78b4;stroke:#1f78b4;\" x=\"401.712397\" xlink:href=\"#md227f39d3a\" y=\"270.208264\"/>\n     <use style=\"fill:#1f78b4;stroke:#1f78b4;\" x=\"286.574153\" xlink:href=\"#md227f39d3a\" y=\"193.448831\"/>\n     <use style=\"fill:#1f78b4;stroke:#1f78b4;\" x=\"159.830503\" xlink:href=\"#md227f39d3a\" y=\"108.953065\"/>\n     <use style=\"fill:#1f78b4;stroke:#1f78b4;\" x=\"44.687603\" xlink:href=\"#md227f39d3a\" y=\"32.191736\"/>\n    </g>\n   </g>\n   <g id=\"text_1\">\n    <g clip-path=\"url(#p0017f4a861)\">\n     <!-- 0 -->\n     <g transform=\"translate(397.894897 273.519514)scale(0.12 -0.12)\">\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-48\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_2\">\n    <g clip-path=\"url(#p0017f4a861)\">\n     <!-- 1 -->\n     <g transform=\"translate(282.756653 196.760081)scale(0.12 -0.12)\">\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-49\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_3\">\n    <g clip-path=\"url(#p0017f4a861)\">\n     <!-- 2 -->\n     <g transform=\"translate(156.013003 112.264315)scale(0.12 -0.12)\">\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-50\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_4\">\n    <g clip-path=\"url(#p0017f4a861)\">\n     <!-- 3 -->\n     <g transform=\"translate(40.870103 35.502986)scale(0.12 -0.12)\">\n      <defs>\n       <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-51\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p0017f4a861\">\n   <rect height=\"288\" width=\"432\" x=\"7.2\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrIFCJnlvGkg"
      },
      "source": [
        "## Documentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7PBwhIKu3et"
      },
      "source": [
        "You can explore more NetworkX functions through its [documentation](https://networkx.org/documentation/stable/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDcCjrW3JWzG"
      },
      "source": [
        "# PyTorch Geometric Tutorial\n",
        "\n",
        "PyTorch Geometric (PyG) is an extension library for PyTorch. It provides useful primitives to develop Graph Deep Learning models, including various graph neural network layers and a large number of benchmark datasets.\n",
        "\n",
        "Don't worry if you don't understand some concepts such as `GCNConv` -- we will cover all of them in the future lectures :)\n",
        "\n",
        "This tutorial is adapted from https://colab.research.google.com/drive/1h3-vJGRVloF5zStxL5I0rSy4ZUPNsjy8?usp=sharing#scrollTo=ci-LpZWhRJoI by [Matthias Fey](https://rusty1s.github.io/#/)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WU7NCZtQ6msa"
      },
      "source": [
        "import torch\n",
        "print(\"PyTorch has version {}\".format(torch.__version__))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch has version 1.8.1+cu111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7gMjMCT677n"
      },
      "source": [
        "## Setup\n",
        "\n",
        "The installation of PyG on Colab can be a little bit tricky. Execute the cell below -- in case of issues, more information can be found on the [PyG's installation page](https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRNEKu-R66Cw"
      },
      "source": [
        "# Install torch geometric\n",
        "!pip install -q torch-scatter -f https://pytorch-geometric.com/whl/torch-1.7.0+cu101.html\n",
        "!pip install -q torch-sparse -f https://pytorch-geometric.com/whl/torch-1.7.0+cu101.html\n",
        "!pip install -q torch-geometric"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLxnaKsN8GVf"
      },
      "source": [
        "## Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qywlcjyr8USw"
      },
      "source": [
        "# Helper function for visualization.\n",
        "%matplotlib inline\n",
        "import torch\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Visualization function for NX graph or PyTorch tensor\n",
        "def visualize(h, color, epoch=None, loss=None):\n",
        "    plt.figure(figsize=(7,7))\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "\n",
        "    if torch.is_tensor(h):\n",
        "        h = h.detach().cpu().numpy()\n",
        "        plt.scatter(h[:, 0], h[:, 1], s=140, c=color, cmap=\"Set2\")\n",
        "        if epoch is not None and loss is not None:\n",
        "            plt.xlabel(f'Epoch: {epoch}, Loss: {loss.item():.4f}', fontsize=16)\n",
        "    else:\n",
        "        nx.draw_networkx(G, pos=nx.spring_layout(G, seed=42), with_labels=False,\n",
        "                         node_color=color, cmap=\"Set2\")\n",
        "    plt.show()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbny-iTO7NQN"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "Recently, deep learning on graphs has emerged to one of the hottest research fields in the deep learning community.\n",
        "Here, **Graph Neural Networks (GNNs)** aim to generalize classical deep learning concepts to irregular structured data (in contrast to images or texts) and to enable neural networks to reason about objects and their relations.\n",
        "\n",
        "This tutorial will introduce you to some fundamental concepts regarding deep learning on graphs via Graph Neural Networks based on the **[PyTorch Geometric (PyG) library](https://github.com/rusty1s/pytorch_geometric)**.\n",
        "PyTorch Geometric is an extension library to the popular deep learning framework [PyTorch](https://pytorch.org/), and consists of various methods and utilities to ease the implementation of Graph Neural Networks.\n",
        "\n",
        "Following [Kipf et al. (2017)](https://arxiv.org/abs/1609.02907), let's dive into the world of GNNs by looking at a simple graph-structured example, the well-known [**Zachary's karate club network**](https://en.wikipedia.org/wiki/Zachary%27s_karate_club). This graph describes a social network of 34 members of a karate club and documents links between members who interacted outside the club. Here, we are interested in detecting communities that arise from the member's interaction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3uPffzbyqn9"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "PyTorch Geometric provides an easy access to the dataset via the [`torch_geometric.datasets`](https://pytorch-geometric.readthedocs.io/en/latest/modules/datasets.html#torch_geometric.datasets) subpackage:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrpL9CtS7nx2"
      },
      "source": [
        "from torch_geometric.datasets import KarateClub\n",
        "\n",
        "dataset = KarateClub()\n",
        "print(f'Dataset: {dataset}:')\n",
        "print('======================')\n",
        "print(f'Number of graphs: {len(dataset)}')\n",
        "print(f'Number of features: {dataset.num_features}')\n",
        "print(f'Number of classes: {dataset.num_classes}')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "libcudart.so.10.1: cannot open shared object file: No such file or directory",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-400b608b2f36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKarateClub\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKarateClub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Dataset: {dataset}:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'======================'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch_geometric/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_debug_enabled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_debug\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch_geometric/data/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtemporal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTemporalData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0min_memory_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInMemoryDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch_geometric/data/data.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_sparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcoalesce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSparseTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m from torch_geometric.utils import (contains_isolated_nodes,\n\u001b[1;32m     10\u001b[0m                                    contains_self_loops, is_undirected)\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch_sparse/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;34m'_saint'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_sample'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_relabel'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m ]:\n\u001b[0;32m---> 14\u001b[0;31m     torch.ops.load_library(importlib.machinery.PathFinder().find_spec(\n\u001b[0m\u001b[1;32m     15\u001b[0m         f'{library}_{suffix}', [osp.dirname(__file__)]).origin)\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_ops.py\u001b[0m in \u001b[0;36mload_library\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;31m# static (global) initialization code in order to register custom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;31m# operators with the JIT.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloaded_libraries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: libcudart.so.10.1: cannot open shared object file: No such file or directory"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCeRGa2q7sdl"
      },
      "source": [
        "After initializing the [`KarateClub`](https://pytorch-geometric.readthedocs.io/en/latest/modules/datasets.html#torch_geometric.datasets.KarateClub) dataset, we first can inspect some of its properties.\n",
        "For example, we can see that this dataset holds exactly **one graph**, and that each node in this dataset is assigned a **34-dimensional feature vector** (which uniquely describes the members of the karate club).\n",
        "Furthermore, the graph holds exactly **4 classes**, which represent the community each node belongs to.\n",
        "\n",
        "Let's now look at the underlying graph in more detail:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTLapYhP7uCn"
      },
      "source": [
        "data = dataset[0]  # Get the first graph object.\n",
        "\n",
        "print(data)\n",
        "print('==============================================================')\n",
        "\n",
        "# Gather some statistics about the graph.\n",
        "print(f'Number of nodes: {data.num_nodes}')\n",
        "print(f'Number of edges: {data.num_edges}')\n",
        "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
        "print(f'Number of training nodes: {data.train_mask.sum()}')\n",
        "print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')\n",
        "print(f'Contains isolated nodes: {data.contains_isolated_nodes()}')\n",
        "print(f'Contains self-loops: {data.contains_self_loops()}')\n",
        "print(f'Is undirected: {data.is_undirected()}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIzbIoc-y8J4"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5zhmKIH72Rf"
      },
      "source": [
        "Each graph in PyTorch Geometric is represented by a single [`Data`](https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#torch_geometric.data.Data) object, which holds all the information to describe its graph representation.\n",
        "We can print the data object anytime via `print(data)` to receive a short summary about its attributes and their shapes:\n",
        "```\n",
        "Data(edge_index=[2, 156], x=[34, 34], y=[34], train_mask=[34])\n",
        "```\n",
        "We can see that this `data` object holds 4 attributes:\n",
        "(1) The `edge_index` property holds the information about the **graph connectivity**, *i.e.*, a tuple of source and destination node indices for each edge.\n",
        "PyG further refers to (2) **node features** as `x` (each of the 34 nodes is assigned a 34-dim feature vector), and to (3) **node labels** as `y` (each node is assigned to exactly one class).\n",
        "(4) There also exists an additional attribute called `train_mask`, which describes for which nodes we already know their community assigments.\n",
        "In total, we are only aware of the ground-truth labels of 4 nodes (one for each community), and the task is to infer the community assignment for the remaining nodes.\n",
        "\n",
        "The `data` object also provides some **utility functions** to infer some basic properties of the underlying graph.\n",
        "For example, we can easily infer whether there exists isolated nodes in the graph (*i.e.* there exists no edge to any node), whether the graph contains self-loops (*i.e.*, $(v, v) \\in \\mathcal{E}$), or whether the graph is undirected (*i.e.*, for each edge $(v, w) \\in \\mathcal{E}$ there also exists the edge $(w, v) \\in \\mathcal{E}$)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFA6Xi4O79r0"
      },
      "source": [
        "from IPython.display import Javascript  # Restrict height of output cell.\n",
        "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n",
        "\n",
        "edge_index = data.edge_index\n",
        "print(edge_index.t())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLLsT0ROzffp"
      },
      "source": [
        "## Edge Index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQJyi9OB8dh_"
      },
      "source": [
        "By printing `edge_index`, we can further understand how PyG represents graph connectivity internally.\n",
        "We can see that for each edge, `edge_index` holds a tuple of two node indices, where the first value describes the node index of the source node and the second value describes the node index of the destination node of an edge.\n",
        "\n",
        "This representation is known as the **COO format (coordinate format)** commonly used for representing sparse matrices.\n",
        "Instead of holding the adjacency information in a dense representation $\\mathbf{A} \\in \\{ 0, 1 \\}^{|\\mathcal{V}| \\times |\\mathcal{V}|}$, PyG represents graphs sparsely, which refers to only holding the coordinates/values for which entries in $\\mathbf{A}$ are non-zero.\n",
        "\n",
        "We can further visualize the graph by converting it to the `networkx` library format, which implements, in addition to graph manipulation functionalities, powerful tools for visualization:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KfJHtlV8h3W"
      },
      "source": [
        "from torch_geometric.utils import to_networkx\n",
        "\n",
        "G = to_networkx(data, to_undirected=True)\n",
        "visualize(G, color=data.y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUdHZY2u8vn3"
      },
      "source": [
        "## Implementing Graph Neural Networks\n",
        "\n",
        "After learning about PyG's data handling, it's time to implement our first Graph Neural Network!\n",
        "\n",
        "For this, we will use one of the most simple GNN operators, the **GCN layer** ([Kipf et al. (2017)](https://arxiv.org/abs/1609.02907)).\n",
        "\n",
        "PyG implements this layer via [`GCNConv`](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.GCNConv), which can be executed by passing in the node feature representation `x` and the COO graph connectivity representation `edge_index`.\n",
        "\n",
        "With this, we are ready to create our first Graph Neural Network by defining our network architecture in a `torch.nn.Module` class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tQGQF8r8zIr"
      },
      "source": [
        "import torch\n",
        "from torch.nn import Linear\n",
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GCN, self).__init__()\n",
        "        torch.manual_seed(12345)\n",
        "        self.conv1 = GCNConv(dataset.num_features, 4)\n",
        "        self.conv2 = GCNConv(4, 4)\n",
        "        self.conv3 = GCNConv(4, 2)\n",
        "        self.classifier = Linear(2, dataset.num_classes)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        h = self.conv1(x, edge_index)\n",
        "        h = h.tanh()\n",
        "        h = self.conv2(h, edge_index)\n",
        "        h = h.tanh()\n",
        "        h = self.conv3(h, edge_index)\n",
        "        h = h.tanh()  # Final GNN embedding space.\n",
        "        \n",
        "        # Apply a final (linear) classifier.\n",
        "        out = self.classifier(h)\n",
        "\n",
        "        return out, h\n",
        "\n",
        "model = GCN()\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zgbaD5P8_M_"
      },
      "source": [
        "Here, we first initialize all of our building blocks in `__init__` and define the computation flow of our network in `forward`.\n",
        "We first define and stack **three graph convolution layers**, which corresponds to aggregating 3-hop neighborhood information around each node (all nodes up to 3 \"hops\" away).\n",
        "In addition, the `GCNConv` layers reduce the node feature dimensionality to $2$, *i.e.*, $34 \\rightarrow 4 \\rightarrow 4 \\rightarrow 2$. Each `GCNConv` layer is enhanced by a [tanh](https://pytorch.org/docs/stable/generated/torch.nn.Tanh.html?highlight=tanh#torch.nn.Tanh) non-linearity.\n",
        "\n",
        "After that, we apply a single linear transformation ([`torch.nn.Linear`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html?highlight=linear#torch.nn.Linear)) that acts as a classifier to map our nodes to 1 out of the 4 classes/communities.\n",
        "\n",
        "We return both the output of the final classifier as well as the final node embeddings produced by our GNN.\n",
        "We proceed to initialize our final model via `GCN()`, and printing our model produces a summary of all its used sub-modules."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48uhs_0j9AMX"
      },
      "source": [
        "model = GCN()\n",
        "\n",
        "_, h = model(data.x, data.edge_index)\n",
        "print(f'Embedding shape: {list(h.shape)}')\n",
        "\n",
        "visualize(h, color=data.y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDtJ9Zjw9I_Y"
      },
      "source": [
        "Remarkably, even before training the weights of our model, the model produces an embedding of nodes that closely resembles the community-structure of the graph.\n",
        "Nodes of the same color (community) are already closely clustered together in the embedding space, although the weights of our model are initialized **completely at random** and we have not yet performed any training so far!\n",
        "This leads to the conclusion that GNNs introduce a strong inductive bias, leading to similar embeddings for nodes that are close to each other in the input graph.\n",
        "\n",
        "### Training on the Karate Club Network\n",
        "\n",
        "But can we do better? Let's look at an example on how to train our network parameters based on the knowledge of the community assignments of 4 nodes in the graph (one for each community):\n",
        "\n",
        "Since everything in our model is differentiable and parameterized, we can add some labels, train the model and observe how the embeddings react.\n",
        "Here, we make use of a semi-supervised or transductive learning procedure: We simply train against one node per class, but are allowed to make use of the complete input graph data.\n",
        "\n",
        "Training our model is very similar to any other PyTorch model.\n",
        "In addition to defining our network architecture, we define a loss critertion (here, [`CrossEntropyLoss`](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)) and initialize a stochastic gradient optimizer (here, [`Adam`](https://pytorch.org/docs/stable/optim.html?highlight=adam#torch.optim.Adam)).\n",
        "After that, we perform multiple rounds of optimization, where each round consists of a forward and backward pass to compute the gradients of our model parameters w.r.t. to the loss derived from the forward pass.\n",
        "If you are not new to PyTorch, this scheme should appear familar to you. \n",
        "Otherwise, the PyTorch docs provide [a good introduction on how to train a neural network in PyTorch](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#define-a-loss-function-and-optimizer).\n",
        "\n",
        "Note that our semi-supervised learning scenario is achieved by the following line:\n",
        "```\n",
        "loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
        "```\n",
        "While we compute node embeddings for all of our nodes, we **only make use of the training nodes for computing the loss**.\n",
        "Here, this is implemented by filtering the output of the classifier `out` and ground-truth labels `data.y` to only contain the nodes in the `train_mask`.\n",
        "\n",
        "Let us now start training and see how our node embeddings evolve over time (best experienced by explicitely running the code):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FI3DETGi9ND6"
      },
      "source": [
        "import time\n",
        "from IPython.display import Javascript  # Restrict height of output cell.\n",
        "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 430})'''))\n",
        "\n",
        "model = GCN()\n",
        "criterion = torch.nn.CrossEntropyLoss()  # Define loss criterion.\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)  # Define optimizer.\n",
        "\n",
        "def train(data):\n",
        "    optimizer.zero_grad()  # Clear gradients.\n",
        "    out, h = model(data.x, data.edge_index)  # Perform a single forward pass.\n",
        "    loss = criterion(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n",
        "    loss.backward()  # Derive gradients.\n",
        "    optimizer.step()  # Update parameters based on gradients.\n",
        "    return loss, h\n",
        "\n",
        "for epoch in range(401):\n",
        "    loss, h = train(data)\n",
        "    # Visualize the node embeddings every 10 epochs\n",
        "    if epoch % 10 == 0:\n",
        "        visualize(h, color=data.y, epoch=epoch, loss=loss)\n",
        "        time.sleep(0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2B3X6tf9YpS"
      },
      "source": [
        "As one can see, our 3-layer GCN model manages to linearly separating the communities and classifying most of the nodes correctly.\n",
        "\n",
        "Furthermore, we did this all with a few lines of code, thanks to the PyTorch Geometric library which helped us out with data handling and GNN implementations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9bELRjibIRO"
      },
      "source": [
        "## Documentation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmqyWVNObNcK"
      },
      "source": [
        "You can explore more PyG functions through its [documentation](https://pytorch-geometric.readthedocs.io/en/latest/)."
      ]
    }
  ]
}